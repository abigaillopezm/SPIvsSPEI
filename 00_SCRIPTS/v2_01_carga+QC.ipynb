{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a944b106",
   "metadata": {},
   "source": [
    "*upd. 14-feb-2026*\n",
    "Se seleccionaron tres estaciones para hacer una evaluación preliminar de los índices SPEI y SPI. Estas están distribuidas en el estado de Jalisco, específicamente, en la zona costa (Puerto Vallarta), centro (Guadalajara) y altos (Lagos Moreno). En esta primera parte del script, se hace la limpieza y análisis exploratorio de los CSV descargados del SMN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a6f8c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#se importan las librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1776db5b",
   "metadata": {},
   "source": [
    "##### Limpieza de los datos\n",
    "1. Se usa `skiprows`y `usecols`para leer desde el principio solo la información necesaria\n",
    "2. Se convierten los valores con la etiqueta NULOS a *NaN*\n",
    "3. Se elimina la fila que contiene strings con las unidades para que no estorben en futuros cálculos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd0b4a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carga_smn(id_estac):\n",
    "    ruta = f\"../01_DATA/raw/dia{id_estac}.txt\"\n",
    "\n",
    "    #Leer los archivos evitando los metadatos para que no estorben al hacer lo cálculos\n",
    "    df = pd.read_csv(ruta, sep='\\\\s+', na_values=['NULO'], usecols = ('FECHA', 'PRECIP','TMAX', 'TMIN'),skiprows=19)\n",
    "    \n",
    "    #Se elimina la fila de las unidades por el mismo motivo anterior\n",
    "    df = df.drop(index=0).reset_index(drop=True)\n",
    "        \n",
    "    #poner columnas en el formato adecuado de variable\n",
    "    df['FECHA'] = pd.to_datetime(df['FECHA'])\n",
    "    cols_df = ['PRECIP', 'TMAX', 'TMIN']\n",
    "    for i in cols_df:\n",
    "        df[i] = pd.to_numeric(df[i], errors = 'coerce')\n",
    "    return df\n",
    "\n",
    "# ---- Para agilizar. se usa un bucle\n",
    "#estacs = [\"14339\",\"14067\", \"14024\", #costa\n",
    "#          \"14066\", \"14065\", \"14169\", #centro\n",
    "#          \"14084\", \"14083\"] #altos\n",
    "\n",
    "estacs = [\"14002\", \"14006\", \"14009\", \"14011\" , \"14016\" , \"14017\" , \"14018\" , \"14023\" , \"14024\",\n",
    "    \"14026\" , \"14028\" , \"14029\" , \"14030\" , \"14032\" , \"14033\" , \"14034\" , \"14035\" , \"14036\" , \"14037\",\n",
    "    \"14038\" , \"14039\" , \"14040\" , \"14044\" , \"14046\" , \"14047\" , \"14048\" , \"14052\" , \"14053\" , \"14054\",\n",
    "    \"14056\" , \"14059\" , \"14060\" , \"14063\" , \"14065\" , \"14066\" , \"14067\" , \"14068\" , \"14070\" , \"14071\",\n",
    "    \"14072\" , \"14075\" , \"14076\" , \"14078\" , \"14080\" , \"14081\" , \"14083\" , \"14084\" , \"14087\" , \"14089\",\n",
    "    \"14090\" , \"14093\" , \"14096\" , \"14099\" , \"14100\" , \"14101\" , \"14104\" , \"14111\" , \"14113\" , \"14114\",\n",
    "    \"14117\" , \"14118\" , \"14119\" , \"14122\" , \"14123\" , \"14125\" , \"14129\" , \"14132\" , \"14136\" , \"14139\",\n",
    "    \"14140\" , \"14141\" , \"14142\" , \"14143\" , \"14144\" , \"14145\" , \"14146\" , \"14155\" , \"14156\" , \"14157\",\n",
    "    \"14160\" , \"14165\" , \"14167\" , \"14168\" , \"14169\" , \"14171\" , \"14179\" , \"14180\" , \"14187\" , \"14189\",\n",
    "    \"14195\" , \"14197\" , \"14198\" , \"14199\" , \"14200\" , \"14202\" , \"14266\" , \"14269\" , \"14297\" , \"14306\",\n",
    "    \"14311\" , \"14320\" , \"14323\" , \"14324\" , \"14326\" , \"14329\" , \"14331\" , \"14336\" , \"14337\" , \"14339\",\n",
    "    \"14343\" , \"14346\" , \"14348\" , \"14349\" , \"14350\" , \"14351\" , \"14355\" , \"14367\" , \"14368\" , \"14369\",\n",
    "    \"14379\" , \"14386\" , \"14391\" , \"14392\" , \"14396\" , \"14397\"]\n",
    "\n",
    "# se hace un diccionario para que no se sobreescriban los archivos\n",
    "estacs_leidas = {}\n",
    "\n",
    "for id_estac in estacs:\n",
    "    resultado = carga_smn(id_estac)\n",
    "    estacs_leidas[id_estac] = resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ba22ea39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       FECHA  PRECIP  TMAX  TMIN\n",
      "0 1980-06-15     NaN   NaN   NaN\n",
      "1 1980-06-16     0.0  31.0  12.0\n",
      "2 1980-06-17     0.0  32.0  18.0\n",
      "3 1980-06-18     0.0  34.0  18.0\n",
      "4 1980-06-19     0.0  32.0  18.0\n",
      "           FECHA  PRECIP  TMAX  TMIN\n",
      "16180 2026-01-30     NaN   NaN   NaN\n",
      "16181 2026-02-01     9.2   NaN   NaN\n",
      "16182 2026-02-02     NaN   NaN   NaN\n",
      "16183 2026-02-04     0.0   NaN   NaN\n",
      "16184 2026-02-05     NaN   NaN   NaN\n"
     ]
    }
   ],
   "source": [
    "print(estacs_leidas['14339'].head())\n",
    "print(estacs_leidas['14339'].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdf151e",
   "metadata": {},
   "source": [
    "##### Control de calidad de los datos\n",
    "\n",
    "**Límites físicos / outliers**\n",
    "* Consistencia térmica: en caso de que Tmax < Tmin, se eliminarán ambos valores\n",
    "* Validación de mínimo: Prcp. no puede ser negativa :. si es negativo se elimina el valor\n",
    "\n",
    "**Estandarización de las fechas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d98e0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando QC para Estación 14002...\n",
      "QC: 0 errores térmicos corregidos. Total: 22291 registros.\n",
      "Procesando QC para Estación 14006...\n",
      "QC: 0 errores térmicos corregidos. Total: 30209 registros.\n",
      "Procesando QC para Estación 14009...\n",
      "QC: 0 errores térmicos corregidos. Total: 29692 registros.\n",
      "Procesando QC para Estación 14011...\n",
      "QC: 0 errores térmicos corregidos. Total: 22304 registros.\n",
      "Procesando QC para Estación 14016...\n",
      "QC: 0 errores térmicos corregidos. Total: 26442 registros.\n",
      "Procesando QC para Estación 14017...\n",
      "QC: 0 errores térmicos corregidos. Total: 26760 registros.\n",
      "Procesando QC para Estación 14018...\n",
      "QC: 0 errores térmicos corregidos. Total: 28421 registros.\n",
      "Procesando QC para Estación 14023...\n",
      "QC: 0 errores térmicos corregidos. Total: 27781 registros.\n",
      "Procesando QC para Estación 14024...\n",
      "QC: 0 errores térmicos corregidos. Total: 23453 registros.\n",
      "Procesando QC para Estación 14026...\n",
      "QC: 0 errores térmicos corregidos. Total: 23671 registros.\n",
      "Procesando QC para Estación 14028...\n",
      "QC: 0 errores térmicos corregidos. Total: 26682 registros.\n",
      "Procesando QC para Estación 14029...\n",
      "QC: 0 errores térmicos corregidos. Total: 18507 registros.\n",
      "Procesando QC para Estación 14030...\n",
      "QC: 0 errores térmicos corregidos. Total: 32715 registros.\n",
      "Procesando QC para Estación 14032...\n",
      "QC: 0 errores térmicos corregidos. Total: 15090 registros.\n",
      "Procesando QC para Estación 14033...\n",
      "QC: 0 errores térmicos corregidos. Total: 17755 registros.\n",
      "Procesando QC para Estación 14034...\n",
      "QC: 0 errores térmicos corregidos. Total: 19145 registros.\n",
      "Procesando QC para Estación 14035...\n",
      "QC: 0 errores térmicos corregidos. Total: 22094 registros.\n",
      "Procesando QC para Estación 14036...\n",
      "QC: 0 errores térmicos corregidos. Total: 23908 registros.\n",
      "Procesando QC para Estación 14037...\n",
      "QC: 0 errores térmicos corregidos. Total: 14957 registros.\n",
      "Procesando QC para Estación 14038...\n",
      "QC: 0 errores térmicos corregidos. Total: 25653 registros.\n",
      "Procesando QC para Estación 14039...\n",
      "QC: 0 errores térmicos corregidos. Total: 28196 registros.\n",
      "Procesando QC para Estación 14040...\n",
      "QC: 0 errores térmicos corregidos. Total: 32801 registros.\n",
      "Procesando QC para Estación 14044...\n",
      "QC: 0 errores térmicos corregidos. Total: 22013 registros.\n",
      "Procesando QC para Estación 14046...\n",
      "QC: 0 errores térmicos corregidos. Total: 17244 registros.\n",
      "Procesando QC para Estación 14047...\n",
      "QC: 0 errores térmicos corregidos. Total: 22115 registros.\n",
      "Procesando QC para Estación 14048...\n",
      "QC: 0 errores térmicos corregidos. Total: 23517 registros.\n",
      "Procesando QC para Estación 14052...\n",
      "QC: 0 errores térmicos corregidos. Total: 25611 registros.\n",
      "Procesando QC para Estación 14053...\n",
      "QC: 0 errores térmicos corregidos. Total: 21084 registros.\n",
      "Procesando QC para Estación 14054...\n",
      "QC: 0 errores térmicos corregidos. Total: 18911 registros.\n",
      "Procesando QC para Estación 14056...\n",
      "QC: 0 errores térmicos corregidos. Total: 20517 registros.\n",
      "Procesando QC para Estación 14059...\n",
      "QC: 0 errores térmicos corregidos. Total: 21504 registros.\n",
      "Procesando QC para Estación 14060...\n",
      "QC: 0 errores térmicos corregidos. Total: 17280 registros.\n",
      "Procesando QC para Estación 14063...\n",
      "QC: 0 errores térmicos corregidos. Total: 18868 registros.\n",
      "Procesando QC para Estación 14065...\n",
      "QC: 0 errores térmicos corregidos. Total: 23910 registros.\n",
      "Procesando QC para Estación 14066...\n",
      "QC: 0 errores térmicos corregidos. Total: 31265 registros.\n",
      "Procesando QC para Estación 14067...\n",
      "QC: 0 errores térmicos corregidos. Total: 23706 registros.\n",
      "Procesando QC para Estación 14068...\n",
      "QC: 0 errores térmicos corregidos. Total: 28097 registros.\n",
      "Procesando QC para Estación 14070...\n",
      "QC: 0 errores térmicos corregidos. Total: 21300 registros.\n",
      "Procesando QC para Estación 14071...\n",
      "QC: 0 errores térmicos corregidos. Total: 10873 registros.\n",
      "Procesando QC para Estación 14072...\n",
      "QC: 0 errores térmicos corregidos. Total: 26277 registros.\n",
      "Procesando QC para Estación 14075...\n",
      "QC: 0 errores térmicos corregidos. Total: 24218 registros.\n",
      "Procesando QC para Estación 14076...\n",
      "QC: 0 errores térmicos corregidos. Total: 27690 registros.\n",
      "Procesando QC para Estación 14078...\n",
      "QC: 0 errores térmicos corregidos. Total: 26111 registros.\n",
      "Procesando QC para Estación 14080...\n",
      "QC: 0 errores térmicos corregidos. Total: 25155 registros.\n",
      "Procesando QC para Estación 14081...\n",
      "QC: 0 errores térmicos corregidos. Total: 25424 registros.\n",
      "Procesando QC para Estación 14083...\n",
      "QC: 0 errores térmicos corregidos. Total: 23423 registros.\n",
      "Procesando QC para Estación 14084...\n",
      "QC: 0 errores térmicos corregidos. Total: 29627 registros.\n",
      "Procesando QC para Estación 14087...\n",
      "QC: 0 errores térmicos corregidos. Total: 22565 registros.\n",
      "Procesando QC para Estación 14089...\n",
      "QC: 0 errores térmicos corregidos. Total: 24399 registros.\n",
      "Procesando QC para Estación 14090...\n",
      "QC: 0 errores térmicos corregidos. Total: 19867 registros.\n",
      "Procesando QC para Estación 14093...\n",
      "QC: 0 errores térmicos corregidos. Total: 27763 registros.\n",
      "Procesando QC para Estación 14096...\n",
      "QC: 0 errores térmicos corregidos. Total: 34782 registros.\n",
      "Procesando QC para Estación 14099...\n",
      "QC: 0 errores térmicos corregidos. Total: 26637 registros.\n",
      "Procesando QC para Estación 14100...\n",
      "QC: 0 errores térmicos corregidos. Total: 27624 registros.\n",
      "Procesando QC para Estación 14101...\n",
      "QC: 0 errores térmicos corregidos. Total: 21949 registros.\n",
      "Procesando QC para Estación 14104...\n",
      "QC: 0 errores térmicos corregidos. Total: 24640 registros.\n",
      "Procesando QC para Estación 14111...\n",
      "QC: 0 errores térmicos corregidos. Total: 26829 registros.\n",
      "Procesando QC para Estación 14113...\n",
      "QC: 0 errores térmicos corregidos. Total: 25061 registros.\n",
      "Procesando QC para Estación 14114...\n",
      "QC: 0 errores térmicos corregidos. Total: 22942 registros.\n",
      "Procesando QC para Estación 14117...\n",
      "QC: 0 errores térmicos corregidos. Total: 21297 registros.\n",
      "Procesando QC para Estación 14118...\n",
      "QC: 0 errores térmicos corregidos. Total: 28940 registros.\n",
      "Procesando QC para Estación 14119...\n",
      "QC: 0 errores térmicos corregidos. Total: 12363 registros.\n",
      "Procesando QC para Estación 14122...\n",
      "QC: 0 errores térmicos corregidos. Total: 29141 registros.\n",
      "Procesando QC para Estación 14123...\n",
      "QC: 0 errores térmicos corregidos. Total: 27975 registros.\n",
      "Procesando QC para Estación 14125...\n",
      "QC: 0 errores térmicos corregidos. Total: 28206 registros.\n",
      "Procesando QC para Estación 14129...\n",
      "QC: 0 errores térmicos corregidos. Total: 20428 registros.\n",
      "Procesando QC para Estación 14132...\n",
      "QC: 0 errores térmicos corregidos. Total: 26648 registros.\n",
      "Procesando QC para Estación 14136...\n",
      "QC: 0 errores térmicos corregidos. Total: 24114 registros.\n",
      "Procesando QC para Estación 14139...\n",
      "QC: 0 errores térmicos corregidos. Total: 19667 registros.\n",
      "Procesando QC para Estación 14140...\n",
      "QC: 0 errores térmicos corregidos. Total: 16786 registros.\n",
      "Procesando QC para Estación 14141...\n",
      "QC: 0 errores térmicos corregidos. Total: 31333 registros.\n",
      "Procesando QC para Estación 14142...\n",
      "QC: 0 errores térmicos corregidos. Total: 29263 registros.\n",
      "Procesando QC para Estación 14143...\n",
      "QC: 0 errores térmicos corregidos. Total: 28769 registros.\n",
      "Procesando QC para Estación 14144...\n",
      "QC: 0 errores térmicos corregidos. Total: 23664 registros.\n",
      "Procesando QC para Estación 14145...\n",
      "QC: 0 errores térmicos corregidos. Total: 30358 registros.\n",
      "Procesando QC para Estación 14146...\n",
      "QC: 0 errores térmicos corregidos. Total: 20182 registros.\n",
      "Procesando QC para Estación 14155...\n",
      "QC: 0 errores térmicos corregidos. Total: 22364 registros.\n",
      "Procesando QC para Estación 14156...\n",
      "QC: 0 errores térmicos corregidos. Total: 27104 registros.\n",
      "Procesando QC para Estación 14157...\n",
      "QC: 0 errores térmicos corregidos. Total: 21614 registros.\n",
      "Procesando QC para Estación 14160...\n",
      "QC: 0 errores térmicos corregidos. Total: 20144 registros.\n",
      "Procesando QC para Estación 14165...\n",
      "QC: 0 errores térmicos corregidos. Total: 26661 registros.\n",
      "Procesando QC para Estación 14167...\n",
      "QC: 0 errores térmicos corregidos. Total: 27382 registros.\n",
      "Procesando QC para Estación 14168...\n",
      "QC: 0 errores térmicos corregidos. Total: 24572 registros.\n",
      "Procesando QC para Estación 14169...\n",
      "QC: 0 errores térmicos corregidos. Total: 26144 registros.\n",
      "Procesando QC para Estación 14171...\n",
      "QC: 0 errores térmicos corregidos. Total: 22255 registros.\n",
      "Procesando QC para Estación 14179...\n",
      "QC: 0 errores térmicos corregidos. Total: 11891 registros.\n",
      "Procesando QC para Estación 14180...\n",
      "QC: 0 errores térmicos corregidos. Total: 26277 registros.\n",
      "Procesando QC para Estación 14187...\n",
      "QC: 0 errores térmicos corregidos. Total: 17467 registros.\n",
      "Procesando QC para Estación 14189...\n",
      "QC: 0 errores térmicos corregidos. Total: 14995 registros.\n",
      "Procesando QC para Estación 14195...\n",
      "QC: 0 errores térmicos corregidos. Total: 9889 registros.\n",
      "Procesando QC para Estación 14197...\n",
      "QC: 0 errores térmicos corregidos. Total: 4751 registros.\n",
      "Procesando QC para Estación 14198...\n",
      "QC: 0 errores térmicos corregidos. Total: 4516 registros.\n",
      "Procesando QC para Estación 14199...\n",
      "QC: 0 errores térmicos corregidos. Total: 3777 registros.\n",
      "Procesando QC para Estación 14200...\n",
      "QC: 0 errores térmicos corregidos. Total: 3437 registros.\n",
      "Procesando QC para Estación 14202...\n",
      "QC: 0 errores térmicos corregidos. Total: 2526 registros.\n",
      "Procesando QC para Estación 14266...\n",
      "QC: 0 errores térmicos corregidos. Total: 22095 registros.\n",
      "Procesando QC para Estación 14269...\n",
      "QC: 0 errores térmicos corregidos. Total: 17747 registros.\n",
      "Procesando QC para Estación 14297...\n",
      "QC: 0 errores térmicos corregidos. Total: 12760 registros.\n",
      "Procesando QC para Estación 14306...\n",
      "QC: 0 errores térmicos corregidos. Total: 15704 registros.\n",
      "Procesando QC para Estación 14311...\n",
      "QC: 0 errores térmicos corregidos. Total: 15871 registros.\n",
      "Procesando QC para Estación 14320...\n",
      "QC: 0 errores térmicos corregidos. Total: 14719 registros.\n",
      "Procesando QC para Estación 14323...\n",
      "QC: 0 errores térmicos corregidos. Total: 2396 registros.\n",
      "Procesando QC para Estación 14324...\n",
      "QC: 0 errores térmicos corregidos. Total: 15412 registros.\n",
      "Procesando QC para Estación 14326...\n",
      "QC: 0 errores térmicos corregidos. Total: 14772 registros.\n",
      "Procesando QC para Estación 14329...\n",
      "QC: 0 errores térmicos corregidos. Total: 15967 registros.\n",
      "Procesando QC para Estación 14331...\n",
      "QC: 0 errores térmicos corregidos. Total: 13145 registros.\n",
      "Procesando QC para Estación 14336...\n",
      "QC: 0 errores térmicos corregidos. Total: 14796 registros.\n",
      "Procesando QC para Estación 14337...\n",
      "QC: 0 errores térmicos corregidos. Total: 15591 registros.\n",
      "Procesando QC para Estación 14339...\n",
      "QC: 0 errores térmicos corregidos. Total: 16185 registros.\n",
      "Procesando QC para Estación 14343...\n",
      "QC: 0 errores térmicos corregidos. Total: 16227 registros.\n",
      "Procesando QC para Estación 14346...\n",
      "QC: 0 errores térmicos corregidos. Total: 15977 registros.\n",
      "Procesando QC para Estación 14348...\n",
      "QC: 0 errores térmicos corregidos. Total: 13799 registros.\n",
      "Procesando QC para Estación 14349...\n",
      "QC: 0 errores térmicos corregidos. Total: 15997 registros.\n",
      "Procesando QC para Estación 14350...\n",
      "QC: 0 errores térmicos corregidos. Total: 15855 registros.\n",
      "Procesando QC para Estación 14351...\n",
      "QC: 0 errores térmicos corregidos. Total: 15789 registros.\n",
      "Procesando QC para Estación 14355...\n",
      "QC: 0 errores térmicos corregidos. Total: 13010 registros.\n",
      "Procesando QC para Estación 14367...\n",
      "QC: 0 errores térmicos corregidos. Total: 10883 registros.\n",
      "Procesando QC para Estación 14368...\n",
      "QC: 0 errores térmicos corregidos. Total: 7471 registros.\n",
      "Procesando QC para Estación 14369...\n",
      "QC: 0 errores térmicos corregidos. Total: 14845 registros.\n",
      "Procesando QC para Estación 14379...\n",
      "QC: 0 errores térmicos corregidos. Total: 15588 registros.\n",
      "Procesando QC para Estación 14386...\n",
      "QC: 0 errores térmicos corregidos. Total: 11294 registros.\n",
      "Procesando QC para Estación 14391...\n",
      "QC: 0 errores térmicos corregidos. Total: 12110 registros.\n",
      "Procesando QC para Estación 14392...\n",
      "QC: 0 errores térmicos corregidos. Total: 10736 registros.\n",
      "Procesando QC para Estación 14396...\n",
      "QC: 0 errores térmicos corregidos. Total: 11530 registros.\n",
      "Procesando QC para Estación 14397...\n",
      "QC: 0 errores térmicos corregidos. Total: 12099 registros.\n"
     ]
    }
   ],
   "source": [
    "def qc_logico(df):   \n",
    "    # 1. Consistencia Térmica: La Máxima no puede ser menor a la Mínima\n",
    "    # Identificamos errores de captura/digitalización\n",
    "    mask_temp_error = df['TMIN'] > df['TMAX']\n",
    "    \n",
    "    # Si TMIN > TMAX, invalidamos ambos registros asignando NaN\n",
    "    df.loc[mask_temp_error, ['TMAX', 'TMIN']] = np.nan\n",
    "    \n",
    "    # 2. Límites Físicos: Valores negativos imposibles\n",
    "    # La precipitación >= 0\n",
    "    df.loc[df['PRECIP'] < 0, 'PRECIP'] = np.nan\n",
    "    \n",
    "    # --- INDEXACIÓN CON FECHAS ---\n",
    "    # 3. Asegurar que FECHA sea tipo datetime\n",
    "    df['FECHA'] = pd.to_datetime(df['FECHA'], errors='coerce')\n",
    "    \n",
    "    # 4. Eliminar duplicados de fecha antes de indexar\n",
    "    df = df.drop_duplicates(subset=['FECHA'])\n",
    "    \n",
    "    # 5. Establecer FECHA como índice\n",
    "    df = df.set_index('FECHA')\n",
    "    \n",
    "    # 6. Ordenar cronológicamente\n",
    "    df = df.sort_index()\n",
    "    \n",
    "    # Reporte de limpieza para seguimiento\n",
    "    # Usamos len(mask_temp_error) o el ID si lo tuviéramos para identificar\n",
    "    print(f\"QC: {mask_temp_error.sum()} errores térmicos corregidos. Total: {len(df)} registros.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# --- BUCLE PARA PROCESAR EL DICCIONARIO ---\n",
    "\n",
    "# Creamos un nuevo diccionario para los datos limpios\n",
    "estaciones_qc = {}\n",
    "\n",
    "for id_estac, df_raw in estacs_leidas.items():\n",
    "    print(f\"Procesando QC para Estación {id_estac}...\")\n",
    "    # Aplicamos la función y guardamos el resultado\n",
    "    estaciones_qc[id_estac] = qc_logico(df_raw)\n",
    "\n",
    "# Ahora puedes acceder a cualquier estación limpia así:\n",
    "# estaciones_qc['14002'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4c488c",
   "metadata": {},
   "source": [
    "##### Integridad de la serie\n",
    "**Faltantes**\n",
    "* Calcular cantidad de datos faltantes\n",
    "* se considerarán las estaciones que contienen más del 90% de los datos\n",
    "* Calidad Mensual: Que no haya meses con más de 5 días faltantes (estos se vuelven NaN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18541fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estación 14002: Calendario normalizado.\n",
      "Estación 14006: Calendario normalizado.\n",
      "Estación 14009: Calendario normalizado.\n",
      "Estación 14011: Calendario normalizado.\n",
      "Estación 14016: Calendario normalizado.\n",
      "Estación 14017: Calendario normalizado.\n",
      "Estación 14018: Calendario normalizado.\n",
      "Estación 14023: Calendario normalizado.\n",
      "Estación 14024: Calendario normalizado.\n",
      "Estación 14026: Calendario normalizado.\n",
      "Estación 14028: Calendario normalizado.\n",
      "Estación 14029: Calendario normalizado.\n",
      "Estación 14030: Calendario normalizado.\n",
      "Estación 14032: Calendario normalizado.\n",
      "Estación 14033: Calendario normalizado.\n",
      "Estación 14034: Calendario normalizado.\n",
      "Estación 14035: Calendario normalizado.\n",
      "Estación 14036: Calendario normalizado.\n",
      "Estación 14037: Calendario normalizado.\n",
      "Estación 14038: Calendario normalizado.\n",
      "Estación 14039: Calendario normalizado.\n",
      "Estación 14040: Calendario normalizado.\n",
      "Estación 14044: Calendario normalizado.\n",
      "Estación 14046: Calendario normalizado.\n",
      "Estación 14047: Calendario normalizado.\n",
      "Estación 14048: Calendario normalizado.\n",
      "Estación 14052: Calendario normalizado.\n",
      "Estación 14053: Calendario normalizado.\n",
      "Estación 14054: Calendario normalizado.\n",
      "Estación 14056: Calendario normalizado.\n",
      "Estación 14059: Calendario normalizado.\n",
      "Estación 14060: Calendario normalizado.\n",
      "Estación 14063: Calendario normalizado.\n",
      "Estación 14065: Calendario normalizado.\n",
      "Estación 14066: Calendario normalizado.\n",
      "Estación 14067: Calendario normalizado.\n",
      "Estación 14068: Calendario normalizado.\n",
      "Estación 14070: Calendario normalizado.\n",
      "Estación 14071: Calendario normalizado.\n",
      "Estación 14072: Calendario normalizado.\n",
      "Estación 14075: Calendario normalizado.\n",
      "Estación 14076: Calendario normalizado.\n",
      "Estación 14078: Calendario normalizado.\n",
      "Estación 14080: Calendario normalizado.\n",
      "Estación 14081: Calendario normalizado.\n",
      "Estación 14083: Calendario normalizado.\n",
      "Estación 14084: Calendario normalizado.\n",
      "Estación 14087: Calendario normalizado.\n",
      "Estación 14089: Calendario normalizado.\n",
      "Estación 14090: Calendario normalizado.\n",
      "Estación 14093: Calendario normalizado.\n",
      "Estación 14096: Calendario normalizado.\n",
      "Estación 14099: Calendario normalizado.\n",
      "Estación 14100: Calendario normalizado.\n",
      "Estación 14101: Calendario normalizado.\n",
      "Estación 14104: Calendario normalizado.\n",
      "Estación 14111: Calendario normalizado.\n",
      "Estación 14113: Calendario normalizado.\n",
      "Estación 14114: Calendario normalizado.\n",
      "Estación 14117: Calendario normalizado.\n",
      "Estación 14118: Calendario normalizado.\n",
      "Estación 14119: Calendario normalizado.\n",
      "Estación 14122: Calendario normalizado.\n",
      "Estación 14123: Calendario normalizado.\n",
      "Estación 14125: Calendario normalizado.\n",
      "Estación 14129: Calendario normalizado.\n",
      "Estación 14132: Calendario normalizado.\n",
      "Estación 14136: Calendario normalizado.\n",
      "Estación 14139: Calendario normalizado.\n",
      "Estación 14140: Calendario normalizado.\n",
      "Estación 14141: Calendario normalizado.\n",
      "Estación 14142: Calendario normalizado.\n",
      "Estación 14143: Calendario normalizado.\n",
      "Estación 14144: Calendario normalizado.\n",
      "Estación 14145: Calendario normalizado.\n",
      "Estación 14146: Calendario normalizado.\n",
      "Estación 14155: Calendario normalizado.\n",
      "Estación 14156: Calendario normalizado.\n",
      "Estación 14157: Calendario normalizado.\n",
      "Estación 14160: Calendario normalizado.\n",
      "Estación 14165: Calendario normalizado.\n",
      "Estación 14167: Calendario normalizado.\n",
      "Estación 14168: Calendario normalizado.\n",
      "Estación 14169: Calendario normalizado.\n",
      "Estación 14171: Calendario normalizado.\n",
      "Estación 14179: Calendario normalizado.\n",
      "Estación 14180: Calendario normalizado.\n",
      "Estación 14187: Calendario normalizado.\n",
      "Estación 14189: Calendario normalizado.\n",
      "Estación 14195: Calendario normalizado.\n",
      "Estación 14197: Calendario normalizado.\n",
      "Estación 14198: Calendario normalizado.\n",
      "Estación 14199: Calendario normalizado.\n",
      "Estación 14200: Calendario normalizado.\n",
      "Estación 14202: Calendario normalizado.\n",
      "Estación 14266: Calendario normalizado.\n",
      "Estación 14269: Calendario normalizado.\n",
      "Estación 14297: Calendario normalizado.\n",
      "Estación 14306: Calendario normalizado.\n",
      "Estación 14311: Calendario normalizado.\n",
      "Estación 14320: Calendario normalizado.\n",
      "Estación 14323: Calendario normalizado.\n",
      "Estación 14324: Calendario normalizado.\n",
      "Estación 14326: Calendario normalizado.\n",
      "Estación 14329: Calendario normalizado.\n",
      "Estación 14331: Calendario normalizado.\n",
      "Estación 14336: Calendario normalizado.\n",
      "Estación 14337: Calendario normalizado.\n",
      "Estación 14339: Calendario normalizado.\n",
      "Estación 14343: Calendario normalizado.\n",
      "Estación 14346: Calendario normalizado.\n",
      "Estación 14348: Calendario normalizado.\n",
      "Estación 14349: Calendario normalizado.\n",
      "Estación 14350: Calendario normalizado.\n",
      "Estación 14351: Calendario normalizado.\n",
      "Estación 14355: Calendario normalizado.\n",
      "Estación 14367: Calendario normalizado.\n",
      "Estación 14368: Calendario normalizado.\n",
      "Estación 14369: Calendario normalizado.\n",
      "Estación 14379: Calendario normalizado.\n",
      "Estación 14386: Calendario normalizado.\n",
      "Estación 14391: Calendario normalizado.\n",
      "Estación 14392: Calendario normalizado.\n",
      "Estación 14396: Calendario normalizado.\n",
      "Estación 14397: Calendario normalizado.\n",
      "\n",
      "--- NORMALIZACIÓN GLOBAL FINALIZADA ---\n",
      "Rango de estudio Jalisco: 1882-04-01 a 2026-02-05\n",
      "Longitud de la serie: 52541 días.\n"
     ]
    }
   ],
   "source": [
    "def integridad_temporal_masiva(diccionario_estaciones):\n",
    "    # 1. Validar que el diccionario no esté vacío\n",
    "    if not diccionario_estaciones:\n",
    "        print(\"El diccionario de estaciones está vacío.\")\n",
    "        return {}\n",
    "\n",
    "    # 2. Identificar la fecha mínima y máxima global de TODO el set de Jalisco\n",
    "    # Recorremos todos los DataFrames para encontrar los extremos temporales\n",
    "    fecha_min_global = min([df.index.min() for df in diccionario_estaciones.values()])\n",
    "    fecha_max_global = max([df.index.max() for df in diccionario_estaciones.values()])\n",
    "    \n",
    "    # 3. Crear el calendario maestro diario (sin saltos)\n",
    "    calendario_maestro = pd.date_range(start=fecha_min_global, end=fecha_max_global, freq='D')\n",
    "    \n",
    "    estaciones_normalizadas = {}\n",
    "    \n",
    "    # 4. Bucle para reindexar cada estación con el calendario maestro\n",
    "    for id_est, df in diccionario_estaciones.items():\n",
    "        # .reindex() es la clave: inserta filas con NaN en las fechas faltantes\n",
    "        df_norm = df.reindex(calendario_maestro)\n",
    "        df_norm.index.name = 'FECHA'\n",
    "        \n",
    "        # Marcamos qué días son \"rellenados\" (útil para auditoría de datos)\n",
    "        # Si PRECIP es NaN, asumimos que es un dato faltante insertado ahora\n",
    "        df_norm['MISSING_DAY'] = df_norm['PRECIP'].isna().astype(int)\n",
    "        \n",
    "        estaciones_normalizadas[id_est] = df_norm\n",
    "        print(f\"Estación {id_est}: Calendario normalizado.\")\n",
    "    \n",
    "    print(f\"\\n--- NORMALIZACIÓN GLOBAL FINALIZADA ---\")\n",
    "    print(f\"Rango de estudio Jalisco: {fecha_min_global.date()} a {fecha_max_global.date()}\")\n",
    "    print(f\"Longitud de la serie: {len(calendario_maestro)} días.\")\n",
    "    \n",
    "    return estaciones_normalizadas\n",
    "\n",
    "# --- EJECUCIÓN ---\n",
    "\n",
    "# Usamos el diccionario 'estaciones_qc' que generamos en el Bloque 2\n",
    "estaciones_listas = integridad_temporal_masiva(estaciones_qc)\n",
    "\n",
    "# Ejemplo de verificación:\n",
    "#print(estaciones_listas['14002'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78254eae",
   "metadata": {},
   "source": [
    "##### Guardar lo anterior como CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5627c48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estación 14002: Guardada con éxito (10958 días).\n",
      "Estación 14006: Guardada con éxito (10958 días).\n",
      "Estación 14009: Guardada con éxito (10958 días).\n",
      "Estación 14011: Guardada con éxito (10958 días).\n",
      "Estación 14016: Guardada con éxito (10958 días).\n",
      "Estación 14017: Guardada con éxito (10958 días).\n",
      "Estación 14018: Guardada con éxito (10958 días).\n",
      "Estación 14023: Guardada con éxito (10958 días).\n",
      "Estación 14024: Guardada con éxito (10958 días).\n",
      "Estación 14026: Guardada con éxito (10958 días).\n",
      "Estación 14028: Guardada con éxito (10958 días).\n",
      "Estación 14029: Guardada con éxito (10958 días).\n",
      "Estación 14030: Guardada con éxito (10958 días).\n",
      "Estación 14032: Guardada con éxito (10958 días).\n",
      "Estación 14033: Guardada con éxito (10958 días).\n",
      "Estación 14034: Guardada con éxito (10958 días).\n",
      "Estación 14035: Guardada con éxito (10958 días).\n",
      "Estación 14036: Guardada con éxito (10958 días).\n",
      "Estación 14037: Guardada con éxito (10958 días).\n",
      "Estación 14038: Guardada con éxito (10958 días).\n",
      "Estación 14039: Guardada con éxito (10958 días).\n",
      "Estación 14040: Guardada con éxito (10958 días).\n",
      "Estación 14044: Guardada con éxito (10958 días).\n",
      "Estación 14046: Guardada con éxito (10958 días).\n",
      "Estación 14047: Guardada con éxito (10958 días).\n",
      "Estación 14048: Guardada con éxito (10958 días).\n",
      "Estación 14052: Guardada con éxito (10958 días).\n",
      "Estación 14053: Guardada con éxito (10958 días).\n",
      "Estación 14054: Guardada con éxito (10958 días).\n",
      "Estación 14056: Guardada con éxito (10958 días).\n",
      "Estación 14059: Guardada con éxito (10958 días).\n",
      "Estación 14060: Guardada con éxito (10958 días).\n",
      "Estación 14063: Guardada con éxito (10958 días).\n",
      "Estación 14065: Guardada con éxito (10958 días).\n",
      "Estación 14066: Guardada con éxito (10958 días).\n",
      "Estación 14067: Guardada con éxito (10958 días).\n",
      "Estación 14068: Guardada con éxito (10958 días).\n",
      "Estación 14070: Guardada con éxito (10958 días).\n",
      "Estación 14071: Guardada con éxito (10958 días).\n",
      "Estación 14072: Guardada con éxito (10958 días).\n",
      "Estación 14075: Guardada con éxito (10958 días).\n",
      "Estación 14076: Guardada con éxito (10958 días).\n",
      "Estación 14078: Guardada con éxito (10958 días).\n",
      "Estación 14080: Guardada con éxito (10958 días).\n",
      "Estación 14081: Guardada con éxito (10958 días).\n",
      "Estación 14083: Guardada con éxito (10958 días).\n",
      "Estación 14084: Guardada con éxito (10958 días).\n",
      "Estación 14087: Guardada con éxito (10958 días).\n",
      "Estación 14089: Guardada con éxito (10958 días).\n",
      "Estación 14090: Guardada con éxito (10958 días).\n",
      "Estación 14093: Guardada con éxito (10958 días).\n",
      "Estación 14096: Guardada con éxito (10958 días).\n",
      "Estación 14099: Guardada con éxito (10958 días).\n",
      "Estación 14100: Guardada con éxito (10958 días).\n",
      "Estación 14101: Guardada con éxito (10958 días).\n",
      "Estación 14104: Guardada con éxito (10958 días).\n",
      "Estación 14111: Guardada con éxito (10958 días).\n",
      "Estación 14113: Guardada con éxito (10958 días).\n",
      "Estación 14114: Guardada con éxito (10958 días).\n",
      "Estación 14117: Guardada con éxito (10958 días).\n",
      "Estación 14118: Guardada con éxito (10958 días).\n",
      "Estación 14119: Guardada con éxito (10958 días).\n",
      "Estación 14122: Guardada con éxito (10958 días).\n",
      "Estación 14123: Guardada con éxito (10958 días).\n",
      "Estación 14125: Guardada con éxito (10958 días).\n",
      "Estación 14129: Guardada con éxito (10958 días).\n",
      "Estación 14132: Guardada con éxito (10958 días).\n",
      "Estación 14136: Guardada con éxito (10958 días).\n",
      "Estación 14139: Guardada con éxito (10958 días).\n",
      "Estación 14140: Guardada con éxito (10958 días).\n",
      "Estación 14141: Guardada con éxito (10958 días).\n",
      "Estación 14142: Guardada con éxito (10958 días).\n",
      "Estación 14143: Guardada con éxito (10958 días).\n",
      "Estación 14144: Guardada con éxito (10958 días).\n",
      "Estación 14145: Guardada con éxito (10958 días).\n",
      "Estación 14146: Guardada con éxito (10958 días).\n",
      "Estación 14155: Guardada con éxito (10958 días).\n",
      "Estación 14156: Guardada con éxito (10958 días).\n",
      "Estación 14157: Guardada con éxito (10958 días).\n",
      "Estación 14160: Guardada con éxito (10958 días).\n",
      "Estación 14165: Guardada con éxito (10958 días).\n",
      "Estación 14167: Guardada con éxito (10958 días).\n",
      "Estación 14168: Guardada con éxito (10958 días).\n",
      "Estación 14169: Guardada con éxito (10958 días).\n",
      "Estación 14171: Guardada con éxito (10958 días).\n",
      "Estación 14179: Guardada con éxito (10958 días).\n",
      "Estación 14180: Guardada con éxito (10958 días).\n",
      "Estación 14187: Guardada con éxito (10958 días).\n",
      "Estación 14189: Guardada con éxito (10958 días).\n",
      "Estación 14195: Guardada con éxito (10958 días).\n",
      "Estación 14197: Guardada con éxito (10958 días).\n",
      "Estación 14198: Guardada con éxito (10958 días).\n",
      "Estación 14199: Guardada con éxito (10958 días).\n",
      "Estación 14200: Guardada con éxito (10958 días).\n",
      "Estación 14202: Guardada con éxito (10958 días).\n",
      "Estación 14266: Guardada con éxito (10958 días).\n",
      "Estación 14269: Guardada con éxito (10958 días).\n",
      "Estación 14297: Guardada con éxito (10958 días).\n",
      "Estación 14306: Guardada con éxito (10958 días).\n",
      "Estación 14311: Guardada con éxito (10958 días).\n",
      "Estación 14320: Guardada con éxito (10958 días).\n",
      "Estación 14323: Guardada con éxito (10958 días).\n",
      "Estación 14324: Guardada con éxito (10958 días).\n",
      "Estación 14326: Guardada con éxito (10958 días).\n",
      "Estación 14329: Guardada con éxito (10958 días).\n",
      "Estación 14331: Guardada con éxito (10958 días).\n",
      "Estación 14336: Guardada con éxito (10958 días).\n",
      "Estación 14337: Guardada con éxito (10958 días).\n",
      "Estación 14339: Guardada con éxito (10958 días).\n",
      "Estación 14343: Guardada con éxito (10958 días).\n",
      "Estación 14346: Guardada con éxito (10958 días).\n",
      "Estación 14348: Guardada con éxito (10958 días).\n",
      "Estación 14349: Guardada con éxito (10958 días).\n",
      "Estación 14350: Guardada con éxito (10958 días).\n",
      "Estación 14351: Guardada con éxito (10958 días).\n",
      "Estación 14355: Guardada con éxito (10958 días).\n",
      "Estación 14367: Guardada con éxito (10958 días).\n",
      "Estación 14368: Guardada con éxito (10958 días).\n",
      "Estación 14369: Guardada con éxito (10958 días).\n",
      "Estación 14379: Guardada con éxito (10958 días).\n",
      "Estación 14386: Guardada con éxito (10958 días).\n",
      "Estación 14391: Guardada con éxito (10958 días).\n",
      "Estación 14392: Guardada con éxito (10958 días).\n",
      "Estación 14396: Guardada con éxito (10958 días).\n",
      "Estación 14397: Guardada con éxito (10958 días).\n",
      "\n",
      "--- PROCESO FINALIZADO ---\n"
     ]
    }
   ],
   "source": [
    "def exportar_rango_especifico(diccionario_normalizado, carpeta_salida, fecha_inicio, fecha_fin):\n",
    "    if not os.path.exists(carpeta_salida):\n",
    "        os.makedirs(carpeta_salida)\n",
    "\n",
    "    for id_est, df in diccionario_normalizado.items():\n",
    "        # 1. Filtrar el DataFrame usando el índice (que es la FECHA)\n",
    "        # .loc es inclusivo en ambos extremos\n",
    "        try:\n",
    "            df_filtrado = df.loc[fecha_inicio : fecha_fin]\n",
    "            \n",
    "            if df_filtrado.empty:\n",
    "                print(f\"Estación {id_est}: Sin datos en el rango {fecha_inicio} a {fecha_fin}. Saltando...\")\n",
    "                continue\n",
    "\n",
    "            # 2. Guardar el archivo filtrado\n",
    "            nombre_archivo = f\"SMN_{id_est}_{fecha_inicio[:4]}_{fecha_fin[:4]}.csv\"\n",
    "            ruta_completa = os.path.join(carpeta_salida, nombre_archivo)\n",
    "            \n",
    "            df_filtrado.to_csv(ruta_completa, sep=',', encoding='utf-8', index=True)\n",
    "            print(f\"Estación {id_est}: Guardada con éxito ({len(df_filtrado)} días).\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error al filtrar la estación {id_est}: {e}\")\n",
    "\n",
    "    print(f\"\\n--- PROCESO FINALIZADO ---\")\n",
    "\n",
    "# --- EJECUCIÓN ---\n",
    "# Define tus fechas de interés (ejemplo: periodo de 30 años)\n",
    "inicio = '1991-01-01'\n",
    "fin = '2020-12-31'\n",
    "carpeta_proyectos = \"../01_DATA/SMN_limpio\"\n",
    "\n",
    "exportar_rango_especifico(estaciones_listas, carpeta_proyectos, inicio, fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2053b4b8",
   "metadata": {},
   "source": [
    "# Selección de estaciones\n",
    "Las estaciones que se trabajaran son las que cumplan los siguientes criterios\n",
    "a) tienen el 90% de registros (datos faltantes < 10%)\n",
    "b) no pueden tener cinco registro nulos seguidos \n",
    "\n",
    "**Se eligió como periodo de 1991 a 2020 (30 años**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc33a5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando filtrado estricto de 125 estaciones...\n",
      "✅ SMN_14002_1991_2020.csv: APTO (Faltantes: 0.0%)\n",
      "❌ SMN_14006_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14009_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14011_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14016_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14017_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14018_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14023_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14024_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14026_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14028_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14029_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14030_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14032_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14033_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14034_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14035_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14036_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14037_1991_2020.csv: Descartado por Total NaNs > 20% (42.3%), Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "✅ SMN_14038_1991_2020.csv: APTO (Faltantes: 0.0%)\n",
      "❌ SMN_14039_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14040_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14044_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14046_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14047_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14048_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14052_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14053_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14054_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14056_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14059_1991_2020.csv: Descartado por Total NaNs > 20% (31.4%), Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14060_1991_2020.csv: Descartado por Total NaNs > 20% (42.3%), Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14063_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14065_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "✅ SMN_14066_1991_2020.csv: APTO (Faltantes: 0.1%)\n",
      "❌ SMN_14067_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14068_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14070_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14071_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14072_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14075_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14076_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14078_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14080_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14081_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14083_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14084_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14087_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14089_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14090_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14093_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14096_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14099_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14100_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14101_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14104_1991_2020.csv: Descartado por Total NaNs > 20% (20.8%), Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14111_1991_2020.csv: Descartado por Total NaNs > 20% (33.7%), Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14113_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14114_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14117_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14118_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14119_1991_2020.csv: Descartado por Total NaNs > 20% (76.4%), Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14122_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14123_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14125_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14129_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14132_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14136_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14139_1991_2020.csv: Descartado por Total NaNs > 20% (64.2%), Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14140_1991_2020.csv: Descartado por Total NaNs > 20% (33.2%), Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14141_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14142_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14143_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14144_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14145_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14146_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14155_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14156_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14157_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14160_1991_2020.csv: Descartado por Total NaNs > 20% (36.3%), Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14165_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14167_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14168_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14169_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14171_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14179_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14180_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14187_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14189_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14195_1991_2020.csv: Descartado por Total NaNs > 20% (26.2%), Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14197_1991_2020.csv: Descartado por Total NaNs > 20% (59.1%), Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14198_1991_2020.csv: Descartado por Total NaNs > 20% (70.2%), Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14199_1991_2020.csv: Descartado por Total NaNs > 20% (75.8%), Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14200_1991_2020.csv: Descartado por Total NaNs > 20% (76.9%), Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14202_1991_2020.csv: Descartado por Total NaNs > 20% (76.9%), Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14266_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14269_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14297_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14306_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14311_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14320_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14323_1991_2020.csv: Descartado por Total NaNs > 20% (95.5%), Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14324_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14326_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14329_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14331_1991_2020.csv: Descartado por Total NaNs > 20% (31.3%), Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14336_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14337_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "✅ SMN_14339_1991_2020.csv: APTO (Faltantes: 0.1%)\n",
      "❌ SMN_14343_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14346_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14348_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14349_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14350_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14351_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14355_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14367_1991_2020.csv: Descartado por Total NaNs > 20% (29.9%), Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14368_1991_2020.csv: Descartado por Total NaNs > 20% (52.4%), Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14369_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14379_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14386_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14391_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14392_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14396_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "❌ SMN_14397_1991_2020.csv: Descartado por Racha >= 10 días NaN, Meses con 10 NaNs\n",
      "\n",
      "--- FILTRADO TERMINADO ---\n",
      "Estaciones finales en 'for_indices': 4\n"
     ]
    }
   ],
   "source": [
    "# --- CONFIGURACIÓN DE RUTAS ---\n",
    "PATH_ENTRADA = \"../01_DATA/SMN_limpio/\"\n",
    "PATH_SALIDA = \"../01_DATA/for_indices\"\n",
    "FECHA_INICIO = \"1991-01-01\"\n",
    "FECHA_FIN = \"2020-12-31\"\n",
    "\n",
    "def tiene_rachas_nan(serie, max_consecutivos=10):\n",
    "    # Creamos una serie booleana (True donde es NaN)\n",
    "    es_nan = serie.isna()\n",
    "    # Identificamos bloques consecutivos de True\n",
    "    # (Comparamos el valor con el anterior para marcar cambios de bloque)\n",
    "    bloques = es_nan.ne(es_nan.shift()).cumsum()\n",
    "    # Contamos el tamaño de cada bloque de NaNs\n",
    "    tamaño_bloques = es_nan.groupby(bloques).transform('sum')\n",
    "    # Si algún bloque de NaNs es >= al límite, devolvemos True\n",
    "    return (tamaño_bloques >= max_consecutivos).any()\n",
    "\n",
    "def filtrar_estaciones_estricto():\n",
    "    archivos = [f for f in os.listdir(PATH_ENTRADA) if f.endswith('.csv')]\n",
    "    aptas = 0\n",
    "    \n",
    "    print(f\"Iniciando filtrado estricto de {len(archivos)} estaciones...\")\n",
    "\n",
    "    for archivo in archivos:\n",
    "        df = pd.read_csv(os.path.join(PATH_ENTRADA, archivo), \n",
    "                         index_col='FECHA', parse_dates=True)\n",
    "        \n",
    "        # 1. Recorte temporal\n",
    "        df_p = df.loc[FECHA_INICIO : FECHA_FIN]\n",
    "        \n",
    "        # 2. Validación de existencia de datos\n",
    "        if df_p.empty or len(df_p) < 1000: # Filtro básico de seguridad\n",
    "            continue\n",
    "\n",
    "        # --- CRITERIOS DE CALIDAD ---\n",
    "        \n",
    "        # A. Máximo 10% de faltantes totales\n",
    "        pct_nan = (df_p['PRECIP'].isna().sum() / len(df_p)) * 100\n",
    "        \n",
    "        # B. No más de 5 días SEGUIDOS con NaN\n",
    "        racha_nan = tiene_rachas_nan(df_p['PRECIP'], max_consecutivos=10)\n",
    "        \n",
    "        # C. No más de 5 días faltantes en UN MES (alternos o no)\n",
    "        # Esto asegura que cada mes sea representativo para el SPI\n",
    "        meses_invalidos = (df_p['PRECIP'].isna().resample('MS').sum() > 10).any()\n",
    "\n",
    "        # --- DECISIÓN FINAL ---\n",
    "        if pct_nan <= 20 and not racha_nan and not meses_invalidos:\n",
    "            ruta_destino = os.path.join(PATH_SALIDA, archivo)\n",
    "            df_p.to_csv(ruta_destino)\n",
    "            aptas += 1\n",
    "            print(f\"✅ {archivo}: APTO (Faltantes: {pct_nan:.1f}%)\")\n",
    "        else:\n",
    "            razon = []\n",
    "            if pct_nan > 20: razon.append(f\"Total NaNs > 20% ({pct_nan:.1f}%)\")\n",
    "            if racha_nan: razon.append(\"Racha >= 10 días NaN\")\n",
    "            if meses_invalidos: razon.append(\"Meses con 10 NaNs\")\n",
    "            print(f\"❌ {archivo}: Descartado por {', '.join(razon)}\")\n",
    "\n",
    "    print(f\"\\n--- FILTRADO TERMINADO ---\")\n",
    "    print(f\"Estaciones finales en 'for_indices': {aptas}\")\n",
    "\n",
    "filtrar_estaciones_estricto()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
